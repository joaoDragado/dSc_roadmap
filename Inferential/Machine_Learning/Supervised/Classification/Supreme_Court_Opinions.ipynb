{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7f5d808c7af3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This function creates images of tree models using pydot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mStringIO\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydot'"
     ]
    }
   ],
   "source": [
    "# TODO : install pydot and port code for python3\n",
    "\n",
    "# This function creates images of tree models using pydot\n",
    "import pydot\n",
    "from StringIO import StringIO\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "\n",
    "def print_tree(estimator, features, class_names=None, filled=True):\n",
    "    tree = estimator\n",
    "    names = features\n",
    "    color = filled\n",
    "    classn = class_names\n",
    "    \n",
    "    dot_data = StringIO()\n",
    "    export_graphviz(estimator, out_file=dot_data, feature_names=features, class_names=classn, filled=filled)\n",
    "    graph = pydot.graph_from_dot_data(dot_data.getvalue())\n",
    "    return(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''If we wish to visualize the decision tree, we should run :'''\n",
    "#graph = print_tree(model, predictor_names)\n",
    "#Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Docket</th>\n",
       "      <th>Term</th>\n",
       "      <th>Circuit</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Petitioner</th>\n",
       "      <th>Respondent</th>\n",
       "      <th>LowerCourt</th>\n",
       "      <th>Unconst</th>\n",
       "      <th>Reverse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93-1408</td>\n",
       "      <td>1994</td>\n",
       "      <td>2nd</td>\n",
       "      <td>EconomicActivity</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>liberal</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93-1577</td>\n",
       "      <td>1994</td>\n",
       "      <td>9th</td>\n",
       "      <td>EconomicActivity</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>liberal</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93-1612</td>\n",
       "      <td>1994</td>\n",
       "      <td>5th</td>\n",
       "      <td>EconomicActivity</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>liberal</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94-623</td>\n",
       "      <td>1994</td>\n",
       "      <td>1st</td>\n",
       "      <td>EconomicActivity</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>conser</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94-1175</td>\n",
       "      <td>1995</td>\n",
       "      <td>7th</td>\n",
       "      <td>JudicialPower</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>conser</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Docket  Term Circuit             Issue Petitioner Respondent LowerCourt  \\\n",
       "0  93-1408  1994     2nd  EconomicActivity   BUSINESS   BUSINESS    liberal   \n",
       "1  93-1577  1994     9th  EconomicActivity   BUSINESS   BUSINESS    liberal   \n",
       "2  93-1612  1994     5th  EconomicActivity   BUSINESS   BUSINESS    liberal   \n",
       "3   94-623  1994     1st  EconomicActivity   BUSINESS   BUSINESS     conser   \n",
       "4  94-1175  1995     7th     JudicialPower   BUSINESS   BUSINESS     conser   \n",
       "\n",
       "   Unconst  Reverse  \n",
       "0        0        1  \n",
       "1        0        1  \n",
       "2        0        1  \n",
       "3        0        1  \n",
       "4        0        1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stevens = pd.read_csv('../data/stevens.csv')\n",
    "#stevens.info()\n",
    "stevens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an effort to achieve better accuracy on our models,\n",
    "we convert all non-numerical variables into categorical ones; for any with multiple values, \n",
    "we will create a new variable for each factor using **pd.get_dummies()**.\n",
    "- Should one use the `drop_first=True` arg in pd.get_dummies(), so as to avoid multi-collinearity issues ?\n",
    "- Need to look into dimensionality reduction et al (PCA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split predictors & response \n",
    "y_pre = stevens.iloc[:,-1]\n",
    "X_pre = stevens.iloc[:,2:8]\n",
    "# turn LowerCourt column into binary values\n",
    "X_pre.LowerCourt = X_pre.LowerCourt.factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count how many distinct variables this wil produce\n",
    "count = 0\n",
    "for i in X_pre.columns:\n",
    "    count += len(X_pre[i].unique())\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explode each categorical valriable into distinct dummy variables\n",
    "X_post = pd.get_dummies(data=X_pre, columns=X_pre.columns[:-2]).astype(int)\n",
    "\n",
    "# merge response & dummy variables to create new dataset\n",
    "stevens = pd.concat([y_pre, X_post],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    51\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigate possible 1-1 correlations between explanatory & responce variables\n",
    "cm = stevens.corr()\n",
    "\n",
    "cm[((cm < -0.6) | (cm > 0.6)) & (cm != 1)].any().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigate possible  multi-collinearity between explanatory variables\n",
    "cm = stevens.iloc[:,1:].corr()\n",
    "cm[((cm < -0.6) | (cm > 0.6)) & (cm != 1)].any().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Use Cross-Validation to evaluate model accuracy\n",
    "\n",
    "- **K** can be any number, but K=10 is generally recommended.\n",
    "- For **classification** problems, `stratified sampling` (via **StratifiedKFold**) is recommended for creating the folds.\n",
    "  - Each response class should be represented with equal proportions in each of the K folds.\n",
    "  - **scikit-learn**'s `cross_val_score` function does this by default.\n",
    "      - When the **cv** argument is an integer, `cross_val_score` uses the **KFold or StratifiedKFold** strategies by default (depending on the absence or presence of the target array).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# re-assign predictor/response variables\n",
    "\n",
    "y = stevens.iloc[:,0]\n",
    "X = stevens.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.593961038961\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "decTree = DTC(max_depth=2)\n",
    "scores = cross_val_score(decTree, X, y, cv=10, scoring='accuracy')\n",
    "#print scores\n",
    "\n",
    "# use average accuracy as an estimate of out-of-sample accuracy\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LowerCourt</td>\n",
       "      <td>0.812121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Respondent_STATE</td>\n",
       "      <td>0.094145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Circuit_9th</td>\n",
       "      <td>0.093734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Respondent_POLITICIAN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Respondent_OTHER</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feature  importance\n",
       "0              LowerCourt    0.812121\n",
       "48       Respondent_STATE    0.094145\n",
       "12            Circuit_9th    0.093734\n",
       "47  Respondent_POLITICIAN    0.000000\n",
       "46       Respondent_OTHER    0.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Gini importance\" of each feature: \n",
    "# the (normalized) total reduction of error brought by that feature\n",
    "decTree.fit(X,y)\n",
    "feat_imp = pd.DataFrame({'feature':X.columns, 'importance':decTree.feature_importances_})\n",
    "# sort & show 5 most important features \n",
    "feat_imp.sort_values(by='importance', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5,  0.6,  0.7,  0.8])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0.5,0.9, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.61673672818409664,\n",
       " 0.668368079289132,\n",
       " 0.668368079289132,\n",
       " 0.668368079289132,\n",
       " 0.5459614946457052]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for an optimal value for one of the model's parameter, \n",
    "# e.g. DecisionTreeClassifier(min_sample_split)\n",
    "p_range = np.arange(0.1,0.6, 0.1)\n",
    "p_scores = []\n",
    "for p in p_range:\n",
    "    decTree = DTC(min_samples_leaf=p)\n",
    "    scores = cross_val_score(decTree, X, y, cv=10, scoring='accuracy')\n",
    "    p_scores.append(scores.mean())\n",
    "p_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.58675096832991569,\n",
       " 0.57250113921166546,\n",
       " 0.61297277284119389,\n",
       " 0.59766005923900667,\n",
       " 0.58111300979722036,\n",
       " 0.58835440874914569,\n",
       " 0.63957051720209612,\n",
       " 0.57995727956254273]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestClassifier(n_estimators)\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "param_range = range(2,10)\n",
    "p_scores = []\n",
    "for p in param_range:\n",
    "    rfc = RFC(min_samples_leaf=0.1, max_depth=p)\n",
    "    scores = cross_val_score(rfc, X, y, cv=10, scoring='accuracy')\n",
    "    p_scores.append(scores.mean())\n",
    "p_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.54305365686944629,\n",
       " 0.54308612440191384,\n",
       " 0.56244702665755297,\n",
       " 0.56949589883800411,\n",
       " 0.59236557302346771,\n",
       " 0.58525290498974702]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN (n_neighbors)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_range = range(25,51,5)\n",
    "p_scores = []\n",
    "for p in param_range:\n",
    "    knn = KNeighborsClassifier(weights='distance', n_neighbors=p)\n",
    "    scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "    p_scores.append(scores.mean())\n",
    "p_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Cross-Validation to evaluate the accuracies of different models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.537413419913\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "print(cross_val_score(logreg, X, y, cv=10, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58525290498974702"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10-fold cross-validation with the best KNearestNeighbors model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=50, weights='distance')\n",
    "cross_val_score(knn, X, y, cv=10, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60286056049213943"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10-fold cross-validation with Random Forests\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "rfc = RFC(min_samples_leaf=0.1)\n",
    "cross_val_score(rfc, X, y, cv=10, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.668368079289132"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10-fold cross-validation with Decision Trees with manually tuned features\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "regTree = DTC(min_samples_leaf=0.2)\n",
    "cross_val_score(regTree, X, y, cv=10, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "- This is approximate, use with iterative approach + mean_score for more consistent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LowerCourt</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Petitioner_US</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Petitioner_BUSINESS</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Petitioner_CITY</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Petitioner_CRIMINAL.DEFENDENT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          feature  importance\n",
       "0                      LowerCourt         1.0\n",
       "37                  Petitioner_US         0.0\n",
       "27            Petitioner_BUSINESS         0.0\n",
       "28                Petitioner_CITY         0.0\n",
       "29  Petitioner_CRIMINAL.DEFENDENT         0.0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Gini importance\" of each feature: \n",
    "# the (normalized) total reduction of error brought by that feature\n",
    "regTree.fit(X,y)\n",
    "feat_imp = pd.DataFrame({'feature':X.columns, 'importance':regTree.feature_importances_})\n",
    "# sort & show 5 most important features \n",
    "feat_imp.sort_values(by='importance', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternate approach using Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.661225222146\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with SVM Classifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svc = SVC(C=0.5, kernel='rbf', class_weight='balanced', gamma=0.05,)\n",
    "scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n",
    "#print scores\n",
    "\n",
    "# use average accuracy as an estimate of out-of-sample accuracy\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Using Cross-Validation & GridSearch for Efficient Discovery of optimal tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''create a parameter grid ; this will be a Dict which maps the parameter names to the values to be searched. '''\n",
    "# various param lists\n",
    "range1 = range(1,10)\n",
    "range2 = range(1,20,2)\n",
    "range3 = range(5,30,2)\n",
    "range4 = range(5,50,5)\n",
    "range5 = [1,2]\n",
    "range6 = range(2,32,2)\n",
    "\n",
    "RFC_grid = dict(n_estimators=range3, min_samples_split=range6, min_samples_leaf=range4)\n",
    "DTC_grid = dict(min_samples_split=range6, min_samples_leaf=range4, class_weight=['balanced', None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the models & corresponding grids ; specify n_jobs=-1 for parallel computation\n",
    "rfc = RFC(class_weight='balanced')\n",
    "dtc = DTC()\n",
    "\n",
    "dtc_grid = GridSearchCV(dtc, DTC_grid, cv=10, scoring='accuracy', n_jobs =-1)\n",
    "rfc_grid = GridSearchCV(rfc, RFC_grid, cv=10, scoring='accuracy', n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.666077738516\n",
      "{'class_weight': 'balanced', 'min_samples_leaf': 35, 'min_samples_split': 2}\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini',\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=35,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "# fit the DTC grid with data\n",
    "dtc_grid.fit(X, y)\n",
    "\n",
    "# examine the best model\n",
    "print(dtc_grid.best_score_)\n",
    "print(dtc_grid.best_params_)\n",
    "print(dtc_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the RFC grid with data\n",
    "rfc_grid.fit(X, y)\n",
    "\n",
    "# examine the best model\n",
    "print(rfc_grid.best_score_)\n",
    "print(rfc_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65397363100615125"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "#from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "regTree = DTC(class_weight='balanced',min_samples_leaf=35, min_samples_split=2)\n",
    "#rf = RFC(n_estimators=7, min_samples_leaf=35, min_samples_split=14)\n",
    "\n",
    "bag = BaggingClassifier(base_estimator=regTree,\n",
    "                        n_estimators=100, \n",
    "                        max_samples=0.7, \n",
    "                        max_features=0.7,\n",
    "                        oob_score=True,\n",
    "                        n_jobs=-1, \n",
    "                        random_state=1)\n",
    "\n",
    "cross_val_score(bag, X, y, cv=7, scoring='accuracy').mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-of-Bag score\n",
    "- compute the out-of-bag **R-squared** score (not MSE, unfortunately!) for given **n_estimators**.\n",
    "- When **n_estimators** is sufficiently large, the **out-of-bag error** is an accurate estimate of **out-of-sample error**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66784452296819785"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag.fit(X,y)\n",
    "bag.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.646643109541\n",
      "{'max_features': 0.35}\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
      "           max_depth=None, max_features=0.35, max_leaf_nodes=None,\n",
      "           min_samples_leaf=35, min_samples_split=4,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=13, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier as ETC\n",
    "\n",
    "ETC_grid = {'max_features':[0.25, 0.35, 0.5]}\n",
    "etc_grid = GridSearchCV(ETC(n_estimators=13, criterion='entropy', min_samples_leaf=35, min_samples_split=4), ETC_grid, cv=10, scoring='accuracy', n_jobs = -1)\n",
    "\n",
    "etc_grid.fit(X,y)\n",
    "# examine the best model\n",
    "print(etc_grid.best_score_)\n",
    "print(etc_grid.best_params_)\n",
    "print(etc_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting\n",
    "\n",
    " - Rather than looking at 200 (say) parallel estimators, We construct a chain of 200 estimators which iteratively refine the results of the previous estimator. \n",
    " - The idea is that by sequentially applying very fast, simple models, we can get a total model error which is better than any of the individual pieces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.648409893993\n",
      "{'min_samples_split': 10, 'n_estimators': 10, 'min_samples_leaf': 35}\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "              min_samples_leaf=35, min_samples_split=10,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "\n",
    "gbc = GBC()\n",
    "params = {'n_estimators':range(10,21,2), 'min_samples_leaf':range(15,51,5), 'min_samples_split':range(10,32,2)}\n",
    "gbc_grid = GridSearchCV(gbc, params, cv=10, scoring='accuracy', n_jobs = -1)\n",
    "gbc_grid.fit(X,y)\n",
    "\n",
    "print(gbc_grid.best_score_)\n",
    "print(gbc_grid.best_params_)\n",
    "print(gbc_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing computational expense using RandomizedSearchCV\n",
    "- Searching many different parameters at once may be computationally infeasible.\n",
    "- **RandomizedSearchCV** searches a subset of the parameters, and you control the computational \"budget\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.648409893993\n",
      "{'n_estimators': 15, 'min_samples_split': 10, 'min_samples_leaf': 30}\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='entropy', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_samples_leaf=30, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=15, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# specify \"parameter distributions\" rather than a \"parameter grid\"\n",
    "range3 = range(5,30,2)\n",
    "range4 = range(5,50,5)\n",
    "range6 = range(2,32,2)\n",
    "\n",
    "RFC_grid = dict(n_estimators=range3, min_samples_split=range6, min_samples_leaf=range4)\n",
    "\n",
    "# instantiate the models & corresponding grids ; specify n_jobs=-1 for parallel computation\n",
    "rfc = RFC(class_weight='balanced', criterion='entropy')\n",
    "\n",
    "# n_iter controls the number of searches\n",
    "rand = RandomizedSearchCV(rfc, RFC_grid, cv=10, scoring='accuracy', n_iter=10, random_state=5)\n",
    "rand.fit(X, y)\n",
    "\n",
    "# examine the best model\n",
    "print(rand.best_score_)\n",
    "print(rand.best_params_)\n",
    "print(rand.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Closing Remarks\n",
    "\n",
    "There is a problem with using the `grid.best_score_` score for evaluation, however.\n",
    "\n",
    "You might be making what is called a **multiple hypothesis testing error**. If you try very many parameter settings, some of them will work better just by chance, and the score that you obtained might not reflect how your model would perform on new unseen data. \n",
    "\n",
    "Therefore, it is good to **split off a separate test-set before performing grid-search**. \n",
    "\n",
    "This pattern can be seen as a **training-validation-test split**, and is common in machine learning:\n",
    "\n",
    "```python\n",
    "# use from sklearn.model_selection import StratifiedShuffleSplit\n",
    "# to create train/test sets X_train, X_test, y_train, y_test\n",
    "\n",
    "# run param grid search on training set\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "cv = KFold(n=len(X_train), n_folds=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "# obtain accuracy on test set\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
